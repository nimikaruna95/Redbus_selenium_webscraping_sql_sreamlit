Redbus_selenium_webscraping_sql_sreamlit

This repository has a solution for scraping, storing, and visualization of data extraction and analysis of bus route from the Redbus website.The project utilizes Selenium for web scraping, SQL for data storage, and Streamlit for data visualization.The main focus is on gathering details about both government and private bus services, including route information, bus types, pricing, star ratings, and seat availability. The utilization of web scraping techniques and developing an interactive application provides valuable insights and an easy-to-use platform for users to explore and filter bus service data.

Table of Contents

- Introduction
- Skills
- Problem Statement
- Approach
- Prerequisites

Introduction:

This project aims to provide a sturdy solution for collecting, analyzing, and visualizing data from the Red Bus platform. It is divided into three primary components:
 1. Web Scraping Using Selenium: Extracts data from the Red Bus website.
 2. SQL Database creation: Inserts the extracted data into a SQL database.
 3. Streamlit App: Visualizes the data stored in the SQL database.

Skills:

- Web Scraping using Selenium
- Python Programming
- Data Visualization with Streamlit
- SQL Database Management

Problem Statement:

The "Redbus Data Scraping and Filtering with Streamlit Application" project focuses on automating the extraction and analysis of bus travel data from the Redbus platform which helps to seeks the revolution for the transportation industry by offering a comprehensive solution for collecting, analyzing, and visualizing bus travel data. Using Selenium for web scraping, the project collects key details such as bus routes, schedules, pricing, and seat availability.By automating data collection, it enhances operational efficiency and supports strategic planning for bus operators and travelers.

Approach:
1.Data Scraping: Utilize Selenium to automate the extraction of data from the Redbus website, including routes, schedules, prices, and seat availability.

2.Data Storage: Store the scraped data in a SQL database.

3.Streamlit Application:Develop a Streamlit application to display and filter the scraped data.Implement filters such as bus type, route, price range, star rating, and availability.

4.Data Analysis: Execute SQL queries to retrieve and filter data based on user inputs.

5.Filtering using Streamlit: Leverage Streamlit to allow users to interact with and filter the data through the application.

6.Prerequisites:
Ensure you have the following installed before starting:
- Python
- Jupyter Notebook
- Selenium
- Streamlit
- SQL Database (e.g., SQLite, MySQL)
